CartPole持续学习指标报告
==================================================

1. 收敛速度 (Convergence Speed)
------------------------------
任务 1 (T1: short+no wind): 32 episodes
任务 2 (T2: short+wind): 47 episodes
任务 3 (T3: long+no wind): 61 episodes
任务 4 (T4: long+wind): 72 episodes
平均收敛速度: 53.0 episodes

2. 平均回报 (Average Reward)
------------------------------
任务 1 (T1: short+no wind): 194.08
任务 2 (T2: short+wind): 362.07
任务 3 (T3: long+no wind): 426.18
任务 4 (T4: long+wind): 416.46
跨任务平均奖励: 349.70

3. 灾难性遗忘 (Catastrophic Forgetting)
------------------------------
任务 1 在训练任务 2 后:
  训练前性能: 29.20
  训练后性能: 399.80
  性能变化: +370.60 (正向迁移)

任务 1 在训练任务 3 后:
  训练前性能: 29.20
  训练后性能: 372.60
  性能变化: +343.40 (正向迁移)

任务 2 在训练任务 3 后:
  训练前性能: 392.60
  训练后性能: 386.20
  性能变化: -6.40 (灾难性遗忘)

任务 1 在训练任务 4 后:
  训练前性能: 29.20
  训练后性能: 370.80
  性能变化: +341.60 (正向迁移)

任务 2 在训练任务 4 后:
  训练前性能: 392.60
  训练后性能: 384.60
  性能变化: -8.00 (灾难性遗忘)

任务 3 在训练任务 4 后:
  训练前性能: 384.60
  训练后性能: 374.60
  性能变化: -10.00 (灾难性遗忘)

任务 2 在训练任务 1 后:
  训练前性能: 392.60
  训练后性能: 401.20
  性能变化: +8.60 (正向迁移)

任务 3 在训练任务 1 后:
  训练前性能: 384.60
  训练后性能: 408.20
  性能变化: +23.60 (正向迁移)

任务 4 在训练任务 1 后:
  训练前性能: 404.40
  训练后性能: 413.60
  性能变化: +9.20 (正向迁移)

4. 熵门控统计 (EGP)
------------------------------
任务 1 (T1: short+no wind): 触发次数=0, 暂停步数=0
任务 2 (T2: short+wind): 触发次数=0, 暂停步数=0
任务 3 (T3: long+no wind): 触发次数=0, 暂停步数=0
任务 4 (T4: long+wind): 触发次数=0, 暂停步数=0

5. 动态遗憾 (Dynamic Regret)
------------------------------
任务 1 (T1: short+no wind):
  平均动态遗憾: 305.92
  奖励曲线总变差(平滑度): 3793.00
  最终奖励EWMA: 349.97
任务 2 (T2: short+wind):
  平均动态遗憾: 137.93
  奖励曲线总变差(平滑度): 2340.00
  最终奖励EWMA: 296.05
任务 3 (T3: long+no wind):
  平均动态遗憾: 73.82
  奖励曲线总变差(平滑度): 680.00
  最终奖励EWMA: 287.96
任务 4 (T4: long+wind):
  平均动态遗憾: 83.54
  奖励曲线总变差(平滑度): 1104.00
  最终奖励EWMA: 304.73

