CartPole持续学习指标报告
==================================================

1. 收敛速度 (Convergence Speed)
------------------------------
任务 1 (T1: short+no wind): 111 episodes
任务 2 (T2: short+wind): 83 episodes
任务 3 (T3: long+no wind): 98 episodes
任务 4 (T4: long+wind): 109 episodes
平均收敛速度: 100.2 episodes

2. 平均回报 (Average Reward)
------------------------------
任务 1 (T1: short+no wind): 116.95
任务 2 (T2: short+wind): 329.67
任务 3 (T3: long+no wind): 426.64
任务 4 (T4: long+wind): 460.27
跨任务平均奖励: 333.38

3. 灾难性遗忘 (Catastrophic Forgetting)
------------------------------
任务 1 在训练任务 2 后:
  训练前性能: 67.80
  训练后性能: 500.00
  性能变化: +432.20 (正向迁移)

任务 1 在训练任务 3 后:
  训练前性能: 67.80
  训练后性能: 500.00
  性能变化: +432.20 (正向迁移)

任务 2 在训练任务 3 后:
  训练前性能: 434.00
  训练后性能: 500.00
  性能变化: +66.00 (正向迁移)

任务 1 在训练任务 4 后:
  训练前性能: 67.80
  训练后性能: 500.00
  性能变化: +432.20 (正向迁移)

任务 2 在训练任务 4 后:
  训练前性能: 434.00
  训练后性能: 500.00
  性能变化: +66.00 (正向迁移)

任务 3 在训练任务 4 后:
  训练前性能: 500.00
  训练后性能: 500.00
  性能变化: +0.00 (正向迁移)

任务 2 在训练任务 1 后:
  训练前性能: 434.00
  训练后性能: 500.00
  性能变化: +66.00 (正向迁移)

任务 3 在训练任务 1 后:
  训练前性能: 500.00
  训练后性能: 500.00
  性能变化: +0.00 (正向迁移)

任务 4 在训练任务 1 后:
  训练前性能: 500.00
  训练后性能: 500.00
  性能变化: +0.00 (正向迁移)

4. 熵门控统计 (EGP)
------------------------------
任务 1 (T1: short+no wind): 触发次数=59, 暂停步数=649
任务 2 (T2: short+wind): 触发次数=59, 暂停步数=649
任务 3 (T3: long+no wind): 触发次数=59, 暂停步数=649
任务 4 (T4: long+wind): 触发次数=59, 暂停步数=649

5. 动态遗憾 (Dynamic Regret)
------------------------------
任务 1 (T1: short+no wind):
  平均动态遗憾: 383.05
  奖励曲线总变差(平滑度): 4395.00
  最终奖励EWMA: 312.26
任务 2 (T2: short+wind):
  平均动态遗憾: 170.33
  奖励曲线总变差(平滑度): 3367.00
  最终奖励EWMA: 246.92
任务 3 (T3: long+no wind):
  平均动态遗憾: 73.36
  奖励曲线总变差(平滑度): 1239.00
  最终奖励EWMA: 270.60
任务 4 (T4: long+wind):
  平均动态遗憾: 39.73
  奖励曲线总变差(平滑度): 874.00
  最终奖励EWMA: 311.24

