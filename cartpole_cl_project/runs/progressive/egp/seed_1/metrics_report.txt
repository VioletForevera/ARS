CartPole持续学习指标报告
==================================================

1. 收敛速度 (Convergence Speed)
------------------------------
任务 1 (T1: short+no wind): 140 episodes
任务 2 (T2: short+wind): 98 episodes
任务 3 (T3: long+no wind): 118 episodes
任务 4 (T4: long+wind): 128 episodes
平均收敛速度: 121.0 episodes

2. 平均回报 (Average Reward)
------------------------------
任务 1 (T1: short+no wind): 91.27
任务 2 (T2: short+wind): 253.55
任务 3 (T3: long+no wind): 500.00
任务 4 (T4: long+wind): 406.33
跨任务平均奖励: 312.79

3. 灾难性遗忘 (Catastrophic Forgetting)
------------------------------
任务 1 在训练任务 2 后:
  训练前性能: 34.60
  训练后性能: 485.40
  性能变化: +450.80 (正向迁移)

任务 1 在训练任务 3 后:
  训练前性能: 34.60
  训练后性能: 500.00
  性能变化: +465.40 (正向迁移)

任务 2 在训练任务 3 后:
  训练前性能: 386.60
  训练后性能: 500.00
  性能变化: +113.40 (正向迁移)

任务 1 在训练任务 4 后:
  训练前性能: 34.60
  训练后性能: 240.40
  性能变化: +205.80 (正向迁移)

任务 2 在训练任务 4 后:
  训练前性能: 386.60
  训练后性能: 247.40
  性能变化: -139.20 (灾难性遗忘)

任务 3 在训练任务 4 后:
  训练前性能: 483.80
  训练后性能: 246.40
  性能变化: -237.40 (灾难性遗忘)

任务 2 在训练任务 1 后:
  训练前性能: 386.60
  训练后性能: 459.60
  性能变化: +73.00 (正向迁移)

任务 3 在训练任务 1 后:
  训练前性能: 483.80
  训练后性能: 454.00
  性能变化: -29.80 (灾难性遗忘)

任务 4 在训练任务 1 后:
  训练前性能: 500.00
  训练后性能: 464.60
  性能变化: -35.40 (灾难性遗忘)

4. 熵门控统计 (EGP)
------------------------------
任务 1 (T1: short+no wind): 触发次数=60, 暂停步数=660
任务 2 (T2: short+wind): 触发次数=60, 暂停步数=660
任务 3 (T3: long+no wind): 触发次数=60, 暂停步数=660
任务 4 (T4: long+wind): 触发次数=60, 暂停步数=660

5. 动态遗憾 (Dynamic Regret)
------------------------------
任务 1 (T1: short+no wind):
  平均动态遗憾: 408.73
  奖励曲线总变差(平滑度): 4776.00
  最终奖励EWMA: 299.39
任务 2 (T2: short+wind):
  平均动态遗憾: 246.45
  奖励曲线总变差(平滑度): 3731.00
  最终奖励EWMA: 176.43
任务 3 (T3: long+no wind):
  平均动态遗憾: 0.00
  奖励曲线总变差(平滑度): 0.00
  最终奖励EWMA: 325.66
任务 4 (T4: long+wind):
  平均动态遗憾: 93.67
  奖励曲线总变差(平滑度): 617.00
  最终奖励EWMA: 261.92

