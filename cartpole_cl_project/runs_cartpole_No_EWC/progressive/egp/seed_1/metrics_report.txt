CartPole持续学习指标报告
==================================================

1. 收敛速度 (Convergence Speed)
------------------------------
任务 1 (T1: short+no wind): 31 episodes
任务 2 (T2: short+wind): 45 episodes
任务 3 (T3: long+no wind): 61 episodes
任务 4 (T4: long+wind): 74 episodes
平均收敛速度: 52.8 episodes

2. 平均回报 (Average Reward)
------------------------------
任务 1 (T1: short+no wind): 188.24
任务 2 (T2: short+wind): 302.94
任务 3 (T3: long+no wind): 402.23
任务 4 (T4: long+wind): 317.69
跨任务平均奖励: 302.77

3. 灾难性遗忘 (Catastrophic Forgetting)
------------------------------
任务 1 在训练任务 2 后:
  训练前性能: 41.40
  训练后性能: 352.00
  性能变化: +310.60 (正向迁移)

任务 1 在训练任务 3 后:
  训练前性能: 41.40
  训练后性能: 324.20
  性能变化: +282.80 (正向迁移)

任务 2 在训练任务 3 后:
  训练前性能: 413.40
  训练后性能: 334.60
  性能变化: -78.80 (灾难性遗忘)

任务 1 在训练任务 4 后:
  训练前性能: 41.40
  训练后性能: 262.00
  性能变化: +220.60 (正向迁移)

任务 2 在训练任务 4 后:
  训练前性能: 413.40
  训练后性能: 289.20
  性能变化: -124.20 (灾难性遗忘)

任务 3 在训练任务 4 后:
  训练前性能: 372.40
  训练后性能: 264.60
  性能变化: -107.80 (灾难性遗忘)

任务 2 在训练任务 1 后:
  训练前性能: 413.40
  训练后性能: 391.80
  性能变化: -21.60 (灾难性遗忘)

任务 3 在训练任务 1 后:
  训练前性能: 372.40
  训练后性能: 398.20
  性能变化: +25.80 (正向迁移)

任务 4 在训练任务 1 后:
  训练前性能: 346.20
  训练后性能: 419.20
  性能变化: +73.00 (正向迁移)

4. 熵门控统计 (EGP)
------------------------------
任务 1 (T1: short+no wind): 触发次数=61, 暂停步数=671
任务 2 (T2: short+wind): 触发次数=61, 暂停步数=671
任务 3 (T3: long+no wind): 触发次数=61, 暂停步数=671
任务 4 (T4: long+wind): 触发次数=61, 暂停步数=671

5. 动态遗憾 (Dynamic Regret)
------------------------------
任务 1 (T1: short+no wind):
  平均动态遗憾: 311.76
  奖励曲线总变差(平滑度): 4888.00
  最终奖励EWMA: 280.45
任务 2 (T2: short+wind):
  平均动态遗憾: 197.06
  奖励曲线总变差(平滑度): 3029.00
  最终奖励EWMA: 259.07
任务 3 (T3: long+no wind):
  平均动态遗憾: 97.77
  奖励曲线总变差(平滑度): 1421.00
  最终奖励EWMA: 279.67
任务 4 (T4: long+wind):
  平均动态遗憾: 182.31
  奖励曲线总变差(平滑度): 1936.00
  最终奖励EWMA: 220.61

