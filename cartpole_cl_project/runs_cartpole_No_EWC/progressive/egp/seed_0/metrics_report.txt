CartPole持续学习指标报告
==================================================

1. 收敛速度 (Convergence Speed)
------------------------------
任务 1 (T1: short+no wind): 30 episodes
任务 2 (T2: short+wind): 45 episodes
任务 3 (T3: long+no wind): 59 episodes
任务 4 (T4: long+wind): 72 episodes
平均收敛速度: 51.5 episodes

2. 平均回报 (Average Reward)
------------------------------
任务 1 (T1: short+no wind): 201.70
任务 2 (T2: short+wind): 331.93
任务 3 (T3: long+no wind): 416.15
任务 4 (T4: long+wind): 398.17
跨任务平均奖励: 336.99

3. 灾难性遗忘 (Catastrophic Forgetting)
------------------------------
任务 1 在训练任务 2 后:
  训练前性能: 31.40
  训练后性能: 314.80
  性能变化: +283.40 (正向迁移)

任务 1 在训练任务 3 后:
  训练前性能: 31.40
  训练后性能: 301.60
  性能变化: +270.20 (正向迁移)

任务 2 在训练任务 3 后:
  训练前性能: 324.80
  训练后性能: 308.60
  性能变化: -16.20 (灾难性遗忘)

任务 1 在训练任务 4 后:
  训练前性能: 31.40
  训练后性能: 307.60
  性能变化: +276.20 (正向迁移)

任务 2 在训练任务 4 后:
  训练前性能: 324.80
  训练后性能: 318.80
  性能变化: -6.00 (灾难性遗忘)

任务 3 在训练任务 4 后:
  训练前性能: 401.40
  训练后性能: 409.40
  性能变化: +8.00 (正向迁移)

任务 2 在训练任务 1 后:
  训练前性能: 324.80
  训练后性能: 306.40
  性能变化: -18.40 (灾难性遗忘)

任务 3 在训练任务 1 后:
  训练前性能: 401.40
  训练后性能: 398.40
  性能变化: -3.00 (灾难性遗忘)

任务 4 在训练任务 1 后:
  训练前性能: 333.00
  训练后性能: 319.00
  性能变化: -14.00 (灾难性遗忘)

4. 熵门控统计 (EGP)
------------------------------
任务 1 (T1: short+no wind): 触发次数=70, 暂停步数=770
任务 2 (T2: short+wind): 触发次数=70, 暂停步数=770
任务 3 (T3: long+no wind): 触发次数=70, 暂停步数=770
任务 4 (T4: long+wind): 触发次数=70, 暂停步数=770

5. 动态遗憾 (Dynamic Regret)
------------------------------
任务 1 (T1: short+no wind):
  平均动态遗憾: 298.30
  奖励曲线总变差(平滑度): 5896.00
  最终奖励EWMA: 320.72
任务 2 (T2: short+wind):
  平均动态遗憾: 168.07
  奖励曲线总变差(平滑度): 2687.00
  最终奖励EWMA: 283.63
任务 3 (T3: long+no wind):
  平均动态遗憾: 83.85
  奖励曲线总变差(平滑度): 1381.00
  最终奖励EWMA: 301.55
任务 4 (T4: long+wind):
  平均动态遗憾: 101.83
  奖励曲线总变差(平滑度): 1782.00
  最终奖励EWMA: 275.81

